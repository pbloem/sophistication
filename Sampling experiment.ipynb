{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble\n",
    "\n",
    "Questions/comments are prefixed by ''&lt;author&gt;:''.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math, random #Jouke: Do we use the former? Can we not just use numpy for the latter?\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPool2D, Dropout, Flatten, Input\n",
    "from keras.layers import Reshape, UpSampling2D\n",
    "import numpy as np\n",
    "\n",
    "import powerlaw\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "pwl = powerlaw.Power_Law(xmin=1, discrete=True, parameters=[1.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def py(d = 0.1):\n",
    "    \"\"\"Something akin to a Pitman-Yor process\"\"\"\n",
    "    members = []\n",
    "    \n",
    "    while True:\n",
    "        if len(members) < 1 or random.random() < d:\n",
    "            draw = random.normalvariate(0, 1.0)\n",
    "        else:\n",
    "            draw = random.choice(members)\n",
    "            \n",
    "        yield draw\n",
    "        members.append(draw)\n",
    "\n",
    "gen = py(0.01)\n",
    "\n",
    "def py_init(shape, dtype=None):\n",
    "    \"\"\"Custom weight initializer for Keras\"\"\" \n",
    "    arr = np.fromfunction(lambda *args: args[0]*0.0 + next(gen), shape=shape)\n",
    "    return arr\n",
    "#     return K.random_normal(shape, dtype=dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Countable Model Class\n",
    "\n",
    "We want a parameterized class of generative networks as models. The parameter values should such that, via a prefix-free encoding, they induce a _meaningful_ prior on the models. We desire a few properties:\n",
    "- Every image of $N$ bits (uncompressed) can be generated by a model taking no input and having a prior probability as close to $2^{-N}$ as possible;\n",
    "- There is a model taking $N$ bits of input such that every image of $N$ bits can be generated by it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience we may fix the size of the output image and pretend the size, $N$, is known to a model. To be completely thorough, this would add $\\log N$ bits to the input of the model. The input of the model is treated as an enumeration of the images generated by it, so strictly speaking the model class should come with a way to scale models to arbitrary input sizes.\n",
    "\n",
    "A large-ish image size limits the impact of small constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uncompressed   196608\n",
      "sophistication 25198\n",
      "noise          19298\n",
      "redundancy     152112\n"
     ]
    }
   ],
   "source": [
    "# The size of the generated image\n",
    "height = width = 128\n",
    "channels = 3\n",
    "\n",
    "# Let's go with 4 bits per pixel per channel (4096 colors)\n",
    "uncompressed = height * width * channels * 4\n",
    "\n",
    "# We divide the uncompressed bits uniformly at random into three types of information\n",
    "_splits = sorted(np.random.choice(uncompressed - 1, 2, replace=False))\n",
    "soph = _splits[0] + 1\n",
    "noise = _splits[1] - _splits[0]\n",
    "redundancy = uncompressed - 1 - _splits[1]\n",
    "\n",
    "print('uncompressed  ', uncompressed)\n",
    "print('sophistication', soph)\n",
    "print('noise         ', noise)\n",
    "print('redundancy    ', redundancy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now tasked with using `soph` bits to initiate a network that takes `noise` bits as input and generates `uncompressed` bits (shaped correctly) as output.\n",
    "When choosing the `soph` bits and the `noise` bits randomly, then, with high probability, the generated image has a _sophistication_ and _noise_ close to `soph` and `noise`, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A typical convolutional neural network (CNN) architecture is `INPUT -> [[CONV -> RELU]*N -> POOL?]*M -> [FC -> RELU]*K -> FC` (http://cs231n.github.io/convolutional-networks/).\n",
    "In order to generate images from unstructured data, we simply reverse this architecture.\n",
    "Note that pooling layers are not invertible.\n",
    "It has been argued that the pooling layers should be replaced by increasing the stride of the convolutions (https://arxiv.org/abs/1412.6806), which suggests a fractional stride for the reverse direction.\n",
    "A fractional stride is implemented by padding each pixel with zeros (indicative of the loss of information in pooling).\n",
    "However, a fractional stride executed like this can introduce artifacts (https://distill.pub/2016/deconv-checkerboard/).\n",
    "Therefore, we choose to invert the pooling layers simply by upscaling.\n",
    "Although ReLU activation is not invertible per se, no expressive power is lost by using ReLU activation for the reverse direction (but filter weights may need to be adjusted)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our architecture comes with many hyperparameters that should ideally be parameters of the model class and hence part of the model encoding.\n",
    "For simplicity, we shall fix them outside the model class and note that the total information represented by the parameters may be low in comparison to the sophistication.\n",
    "The hyperparameters are\n",
    "\n",
    "- The number of layers in the fully connected part and for each layer\n",
    "  - The number of cells;\n",
    "- The number of convolution blocks and for each block\n",
    "  - The number of convolutions and for each convolution\n",
    "    - The size of the filter (height, width, depth);\n",
    "\n",
    "Upsampling happens after each block of convolutions and is conveniently done by a factor 2 in the height and width."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters determine the number of weights that must be encoded in the sophistication.\n",
    "Typically, weights in a CNN are not distributed uniformly at random and a trained network can be compressed substantially.\n",
    "We distinguish two approaches to compressing neural networks:\n",
    "1. Invasive (e.g. pruning, [LeCun et al., 1989; Guo et al., 2016])\n",
    "2. Non-invasive (e.g. quantization [Gupta et al., 2015])\n",
    "The second approach comes in fixed-length and variable-length versions and differs in the amount of reproduction accuracy required accross the literature.\n",
    "While variable-length and invasive techniques may produce better results, we choose to focus on fixed-length quantization.\n",
    "If needed, it is possible to account for an additional `X%` improvement obtainable by different methods via an implicit `X/(1-X)%` increase in the available sophistication.\n",
    "\n",
    "Experiments have shown that weights in a CNN typically follow a Laplace (two-sided exponential) distribution that has lower variance in layers further away from the image.\n",
    "Quantizing with such a distribution, around 5 bits of accuracy are needed for acceptable performance (http://vijaychan.github.io/Publications/dcc-2017-cnn-compression.pdf).\n",
    "However, in typical networks (e.g. AlexNet and VGG) the number of weights is dominated by the weights in the fully connected layer, for which our simple quantization scheme is of no use.\n",
    "In deep convolutional networks (e.g. ResNet), most weights reside in convolutional layers.\n",
    "We strive to keep the fully connected layer as small as possible, while still realizing the properties we desire of our model class.\n",
    "In particular, when all information resides in the sophistication, we should resort to a simple fully connected layer where the weight encodes all information in a channel of a pixel (i.e. 4 bits).\n",
    "\n",
    "It has been observed that CNNs with random filters are able to perform well.\n",
    "This suggests that information can be pushed to the fully connected layer.\n",
    "We shall not be too concerned with this and try to put the information in the convolutional layers.\n",
    "\n",
    "From Wikipedia:\n",
    "> **Number of filters**\n",
    ">\n",
    "> Since feature map size decreases with depth, layers near the input layer will tend to have fewer filters while higher layers can have more.\n",
    "> To equalize computation at each layer, the feature x pixel position product is kept roughly constant across layers.\n",
    "> Preserving more information about the input would require keeping the total number of activations (number of feature maps times number of pixel positions) non-decreasing from one layer to the next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick and Dirty\n",
    "\n",
    "Let's ignore the fully connected layer for a moment.\n",
    "There are roughly `soph // 5` weight variables available (drawn from Laplace distributions with varying variance).\n",
    "\n",
    "The output image is `height * width * channels`, whereas the input is `1 * 1 * noise`.\n",
    "Suppose we keep the kernel size fixed throughout the network: **`kernelsize`**.\n",
    "To make all values in the first filter useful, we reshape the noise to be wider and higher than this kernel size: **`reshapesize`** (`reshapedepth = noise // reshapesize ** 2`).\n",
    "Upsampling inbetween blocks, we thus need `numblocks = log (height / reshapesize) + 1` convolution blocks.\n",
    "Let's say we decrease the depth by a constant factor in each block.\n",
    "The corresponding factor is `depthfactor = (channels / reshapedepth) ** (1 / numblocks)`.\n",
    "\n",
    "We can now calculate the number of weights in the network.\n",
    "Each convolution in block `i` (here: one-based) has `kernelsize ** 2 * reshapedepth ** 2 * depthfactor ** (2 * i - 1)` weights.\n",
    "\n",
    "### Assumptions\n",
    "- there is enough noise to reshape (`noise > reshapesize ** 2`)\n",
    "- we keep the kernelsize constant throughout the network\n",
    "- we keep the blockdepth constant throughout the network\n",
    "- the filterdepth decreases by a constant factor in every block "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum sensible number of weights: 5573518.8\n"
     ]
    }
   ],
   "source": [
    "def network_parameters(kernelsize):\n",
    "    \"\"\"the reshapesize, reshapedepth, number of blocks and depthfactor corresponding to a kernelsize\"\"\"\n",
    "    reshapesize = int(2 ** np.ceil(np.log2(kernelsize)))\n",
    "    reshapedepth = noise // reshapesize ** 2\n",
    "    numblocks = int(np.log2(height) - np.log2(reshapesize)) + 1\n",
    "    depthfactor = (channels / reshapedepth) ** (1 / numblocks)\n",
    "    return (reshapesize, reshapedepth, numblocks, depthfactor)\n",
    "\n",
    "def number_of_weights(kernelsize, blockdepth):\n",
    "    _, reshapedepth, numblocks, depthfactor = network_parameters(kernelsize)\n",
    "    \"\"\"The number of weights for a given kernelsize and (constant) number of convolutions per block\"\"\"\n",
    "    return sum(blockdepth * kernelsize ** 2 * reshapedepth ** 2 * depthfactor ** (2 * i + 1)\n",
    "               for i in range(numblocks))\n",
    "\n",
    "print(\"Minimum sensible number of weights: {:.1f}\".format(number_of_weights(3, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target number of weights: 5039.6\n"
     ]
    }
   ],
   "source": [
    "# We use quantization based on a Laplace distribution, resulting in a reduced number of Bits Per Weight\n",
    "# NB: for optimal results, the variance of the distribution should vary throughout the network\n",
    "bpw = 5\n",
    "weights = soph / bpw\n",
    "print('Target number of weights:', weights)\n",
    "for d in range(1, 10):\n",
    "    for k in range(10, 1, -1):\n",
    "        w = number_of_weights(k, d) \n",
    "        if w < weights:\n",
    "            print(\"Possible number of weights: {:.1f} (kernelsize: {}, blockdepth: {})\".format(w, k, d))\n",
    "            #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f5b2078a7a28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Out-of-band parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mkernelsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mblockdepth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnumber_of_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernelsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'kernelsize'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernelsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'blockdepth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblockdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "# Out-of-band parameters\n",
    "kernelsize = 5\n",
    "blockdepth = max(d for d in range(1, 10) if number_of_weights(kernelsize, d) < weights)\n",
    "print('kernelsize', kernelsize)\n",
    "print('blockdepth', blockdepth)\n",
    "\n",
    "# Derived parameters\n",
    "reshapesize, reshapedepth, numblocks, depthfactor = network_parameters(kernelsize)\n",
    "print('reshapesize ', reshapesize)\n",
    "print('reshapedepth', reshapedepth)\n",
    "print('numblocks   ', numblocks)\n",
    "print('depthfactor ', depthfactor)\n",
    "\n",
    "def initializer_laplace(shape, dtype=None):\n",
    "    \"\"\"Samples from a laplace distribution\"\"\"\n",
    "    # TODO:\n",
    "    # - truncate precision to `bpw` bits\n",
    "    # - vary variance\n",
    "    return np.random.laplace(size=shape)\n",
    "\n",
    "x = encoded = Input(shape=(reshapesize, reshapesize, int(np.ceil(reshapedepth))))\n",
    "for i in range(1, numblocks): # One too few\n",
    "    for b in range(blockdepth):\n",
    "        x = Conv2D(int(np.ceil(reshapedepth * depthfactor ** i)), (kernelsize, kernelsize),\n",
    "                   activation='relu', padding='same', kernel_initializer=initializer_laplace)(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "for b in range(blockdepth): # The remaining one (without upsampling)\n",
    "    x = Conv2D(channels, (kernelsize, kernelsize),\n",
    "               activation='relu', padding='same', kernel_initializer=initializer_laplace)(x)\n",
    "\n",
    "#Jouke: We want to bring the outputs inside [0, 1] somehow...\n",
    "\n",
    "decoder = Model(encoded, x)\n",
    "\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oops, we have over a factor 1000 too many weights in this model class. We need to cut down on the depth of layers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peter's Model\n",
    "\n",
    "Currently, the topology is a series of `numblocks` stacks of `blockdepth` consecutive 2D convolutions, separated by upsampling layers.\n",
    "There is also a dense layer following the input.\n",
    "This topology is fairly standard (http://cs231n.github.io/convolutional-networks/).\n",
    "\n",
    "**Questions Jouke has**:\n",
    "- To what extent is a this standard network layout (`INPUT -> [[CONV -> RELU]*N -> POOL?]*M -> [FC -> RELU]*K -> FC`, see the above Stanford link) theoretically invertible?\n",
    "- What is the difference between convolutions and transpose convolutions (from https://arxiv.org/pdf/1603.07285.pdf I understand that each can be expressed as the other), and why do we prefer the former?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample a model\n",
    "\n",
    "# number of blocks of k convolutions and \n",
    "input_dim = int(pwl.generate_random()[0])\n",
    "print('input_dim\\t', input_dim)\n",
    "\n",
    "num_channels = int(pwl.generate_random()[0])\n",
    "print('num_channels\\t', num_channels)\n",
    "\n",
    "numblocks = random.randint(1,13) # this should be unbounded for a proper model class\n",
    "print('numblocks\\t', numblocks)\n",
    "\n",
    "blockdepth = random.randint(1,7)\n",
    "print('blockdepth\\t', blockdepth)\n",
    "\n",
    "kernelsize = random.randint(1,10)\n",
    "print('kernelsize\\t', kernelsize)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the PY weight generator\n",
    "# gen=py(0.2)\n",
    "\n",
    "encoded = Input(shape=(input_dim,))\n",
    "\n",
    "x = Dense(256, activation='relu')(encoded)\n",
    "x = Reshape((4,4,16))(x)\n",
    "\n",
    "for n in range(numblocks):\n",
    "    for b in range(blockdepth):\n",
    "        x = Conv2D(num_channels, (kernelsize, kernelsize), activation='relu', padding='same', kernel_initializer=py_init)(x)\n",
    "        \n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "        \n",
    "decoded = Conv2D(3, (4, 4), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "decoder = Model(encoded, decoded)\n",
    "\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 12\n",
    "\n",
    "z = np.random.randn(n, input_dim) #Jouke: why take a normal distribution over the input?\n",
    "y = decoder.predict(z)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "# plot several images\n",
    "for i in range(n):\n",
    "    ax = fig.add_subplot(3, 4, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(y[i,...])\n",
    "    \n",
    "plt.savefig('random-images.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
